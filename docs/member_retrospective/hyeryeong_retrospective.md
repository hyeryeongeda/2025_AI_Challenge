# 🧠 Member Retrospective (개인 회고)

## 🙋‍♀️ 역할 (Role)
- **Inference / Prompt / 모델 최종 성능 개선 담당**
- Notebook 단일 파일(`E026_NULL 먹던걸로.ipynb`)에서 학습~추론~제출까지 전체 흐름 구축

---

## ✅ 4일동안 조원들과 한 일 (Contribution)

| 분야 | 수행 내용 |
|------|-----------|
| **모델 실험 / 선정** | Qwen2.5-VL → **Qwen3-VL-4B-Instruct**로 변경하여 성능 개선 |
| **데이터 처리** | `train_df.sample(n=200)` → **400개로 확장**하여 Generalization 향상 |
| **LoRA Fine-tuning** | `r=8 → 16`, `alpha=16 → 64`로 세부 학습 표현 능력 강화 |
| **이미지 처리** | `IMAGE_SIZE = 384 → 448`로 세부 시각적 패턴을 더 정확히 반영하도록 변경 |
| **학습 안정화** | EPOCH 2, LR=2e-4 로 최적화하여 Loss 안정화 |
| **Prompt Engineering** | 한국어 프롬프트 → **영어 프롬프트**로 변경해 LLM 학습 구조에 맞춤 |

---

## 📌 왜 그렇게 했는가 (Decision & Reasoning)

| 선택 | 이유 |
|------|------|
| **Qwen3-VL-4B-Instruct 선택** | 3B 대비 이해도 및 멀티모달 추론력이 더 좋음 |
| **Image Size 증가** | 이미지 내부 작은 텍스트/사물 인식률 향상 |
| **학습 데이터 수 증가 (200 → 400)** | 초기 Loss 변동이 줄고, 과적합 완화됨 |
| **LoRA r/alpha 증가** | 세부 feature 표현 능력 증가 → 답변 일관성 ↑ |
| **영어 Prompt 적용** | LLM 사전학습 분포가 영어 중심 → 답변 정확도 ↑ |

---

## 🧪 문제 해결 과정 (Troubleshooting)

| 상황 | 해결한 방법 |
|------|-------------|
| 모델이 선택지를 잘 선택하지 않음 | 프롬프트에 *“Answer with only a, b, c, d”* 제약 추가 |
| 이미지 속 세부 정보 인식을 못함 | IMAGE_SIZE 를 448로 증가하여 시각 특징 강화 |
| 학습 초기에 Loss 변동 크게 발생 | 데이터 양을 400개로 증가 |
| LoRA 미세조정 효과가 약함 | r/alpha 를 증가시켜 표현력 개선 |

---

## ✨ 배운 점 (Key Learning)

- **추론(Inference)이 성능의 절반 이상을 결정한다.**  
  학습 성능이 같아도 프롬프트+추론 전략(TTA 등)으로 점수가 크게 달라짐.

- **모델 크기보다 “모델이 어떤 데이터로 학습되었는지”가 중요하다.**

- **변경사항을 한 번에 많이 바꾸지 말고, 실험 로그를 남기면서 진행해야 한다.**  
  (변수 통제를 통해 "무엇이 성능을 개선했는가"를 명확히 확인 가능)

---

## 🚀 다음에 하고 싶은 개선

- LoRA → QLoRA 로 VRAM 절약 & 더 큰 모델 실험
- Few-shot Prompting, CoT 프롬프트 적용해서 reasoning 강화
- Feature caching 으로 반복 TTA 속도 개선

---

> 이 프로젝트에서 얻은 가장 큰 성과는 **“성능을 올리는 과정 자체를 증명할 수 있었다”** 는 점.

